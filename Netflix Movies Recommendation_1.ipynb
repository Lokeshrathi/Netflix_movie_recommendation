{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Reading dataset file\ndataset = pd.read_csv('/kaggle/input/netflix-prize-data/combined_data_1.txt',header = None, names = ['Cust_Id', 'Rating'], usecols = [0,1])\n\n# Convert Ratings column to a float\ndataset['Rating'] = dataset['Rating'].astype(float)\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#To print the datatype of columns\ndataset.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#To inspect the shape of the datset\ndataset.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#To print the head of dataset\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#To find the distribution of different ratings in the datset\nd = dataset['Rating'].value_counts()\nd =pd.DataFrame(d)\nd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movie_count = dataset['Rating'].isnull().sum()\nmovie_count","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Observation\n-  The number of movies is 4499","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# get customer count\ncust_count = dataset['Cust_Id'].nunique()-movie_count\n\ncust_count","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Observation\n\n- The number of customers is 470758","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# get rating count\n\nrating_count = dataset['Cust_Id'].count() - movie_count\nrating_count","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Observation\n\n- The total number of ratings is 24053764","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## To plot the distribution of the ratings in as a bar plot","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nax = d.plot(kind = 'barh', legend = False, figsize = (15,10))\nplt.title(f'Total pool: {movie_count} Movies, {cust_count} customers, {rating_count} ratings given', fontsize=20)\nplt.axis('On')\n\nfor i in range(1,6):\n    ax.text(d.iloc[i-1][0]/4, i-1,'Rating {}: {:.0f}%'.format(i, d.iloc[i-1][0]*100 / d.sum()[0]), color = 'white', weight = 'bold')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To count all the 'nan' values in the Ratings column in the 'ratings' dataset\ndf_nan = pd.DataFrame(pd.isnull(dataset.Rating),)\n\ndf_nan.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.isnull(dataset['Rating'])\ndf1 = pd.DataFrame(df)\ndf2 = df1[df1['Rating']==True]\ndf2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Now we know all that where does the movies counting start from","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = df2.reset_index()\ndf_nan = df2.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_nan","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#To create a numpy array containing movie ids according the 'ratings' dataset\n\nmovie_np = []\nmovie_id = 1\n\nfor i,j in zip(df_nan['index'][1:],df_nan['index'][:-1]):\n    # numpy approach\n    temp = np.full((1,i-j-1), movie_id)\n    movie_np = np.append(movie_np, temp)\n    movie_id += 1\n\n# Account for last record and corresponding length\n# numpy approach\nlast_record = np.full((1,len(dataset) - df_nan.iloc[-1, 0] - 1),movie_id)\nmovie_np = np.append(movie_np, last_record)\n\n#print(f'Movie numpy: {movie_np}')\n#print(f'Length: {len(movie_np)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#To append the above created array to the datset after removing the 'nan' rows\ndataset = dataset[pd.notnull(dataset['Rating'])]\n\ndataset['Movie_Id'] = movie_np.astype(int)\ndataset['Cust_Id'] =dataset['Cust_Id'].astype(int)\nprint('-Dataset examples-')\ndataset.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f = ['count','mean']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#To create a list of all the movies rated less often(only include top 30% rated movies)\ndataset_movie_summary = dataset.groupby('Movie_Id')['Rating'].agg(f)\n\ndataset_movie_summary.index = dataset_movie_summary.index.map(int)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movie_benchmark = round(dataset_movie_summary['count'].quantile(0.7),0)\n\ndrop_movie_list = dataset_movie_summary[dataset_movie_summary['count'] < movie_benchmark].index\n\nprint('Movie minimum times of review: {}'.format(movie_benchmark))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#To create a list of all the inactive users(users who rate less often)\ndataset_cust_summary = dataset.groupby('Cust_Id')['Rating'].agg(f)\ndataset_cust_summary.index = dataset_cust_summary.index.map(int)\ncust_benchmark = round(dataset_cust_summary['count'].quantile(0.7),0)\ndrop_cust_list = dataset_cust_summary[dataset_cust_summary['count'] < cust_benchmark].index\n\nprint(f'Customer minimum times of review: {cust_benchmark}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Original Shape: {dataset.shape}')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = dataset[~dataset['Movie_Id'].isin(drop_movie_list)]\ndataset = dataset[~dataset['Cust_Id'].isin(drop_cust_list)]\nprint('After Trim Shape: {}'.format(dataset.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('-Data Examples-')\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create ratings matrix for 'ratings' matrix with Rows = userId, Columns = movieId","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_p = pd.pivot_table(dataset,values='Rating',index='Cust_Id',columns='Movie_Id')\n\nprint(df_p.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_title = pd.read_csv('/kaggle/input/netflix-prize-data/movie_titles.csv', encoding = \"ISO-8859-1\", header = None, names = ['Movie_Id', 'Year', 'Name'])\n\ndf_title.set_index('Movie_Id', inplace = True)\n\nprint (df_title.head(10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# To install the scikit-surprise library for implementing SVD","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import required libraries\nimport math\nimport re\nimport matplotlib.pyplot as plt\n\nfrom surprise import Reader, Dataset, SVD\nfrom surprise.model_selection import cross_validate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load Reader library\nreader = Reader()\n\n# get just top 100K rows for faster run time\ndata = Dataset.load_from_df(dataset[['Cust_Id', 'Movie_Id', 'Rating']][:100000], reader)\n\n# Use the SVD algorithm.\nsvd = SVD()\n\n# Compute the RMSE of the SVD algorithm\ncross_validate(svd, data, measures=['RMSE', 'MAE'], cv=3, verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_712664 = dataset[(dataset['Cust_Id'] == 712664) & (dataset['Rating'] == 5)]\ndataset_712664 = dataset_712664.set_index('Movie_Id')\ndataset_712664 = dataset_712664.join(df_title)['Name']\ndataset_712664.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train an SVD to predict ratings for user with userId = 1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a shallow copy for the movies dataset\nuser_712664 = df_title.copy()\n\nuser_712664 = user_712664.reset_index()\n\n#To remove all the movies rated less often \nuser_712664 = user_712664[~user_712664['Movie_Id'].isin(drop_movie_list)]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting full dataset\ndata = Dataset.load_from_df(dataset[['Cust_Id', 'Movie_Id', 'Rating']], reader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create a training set for svd\ntrainset = data.build_full_trainset()\nsvd.fit(trainset)\n\n#Predict the ratings for user_712664\nuser_712664['Estimate_Score'] = user_712664['Movie_Id'].apply(lambda x: svd.predict(712664, x).est)\n\n#Drop extra columns from the user_712664 data frame\nuser_712664 = user_712664.drop('Movie_Id', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sort predicted ratings for user_712664 in descending order\nuser_712664 = user_712664.sort_values('Estimate_Score', ascending=False)\n\n#Print top 10 recommendations\nprint(user_712664.head(10))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}